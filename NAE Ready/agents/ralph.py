# NAE/agents/ralph.py
"""
RalphAgent v4 - Enhanced Learning Agent with Market Data Integration and QuantConnect Backtesting

Features:
- Real-time market data integration via Polygon.io with rate limiting
- QuantConnect backtesting integration for professional-grade strategy validation
- Enhanced AI source ingestion (Grok, DeepSeek, Claude) with improved reliability
- Web scraping and forum content ingestion with error handling
- Advanced backtesting with walk-forward analysis and risk metrics
- Comprehensive trust/quality scoring with multiple validation layers
- Professional-grade strategy filtering and risk assessment
- Immutable audit logging for regulatory compliance
- Configurable thresholds and extensive logging for audit by Bebop/Splinter/Phisher

ALIGNED WITH 3 CORE GOALS:
1. Achieve generational wealth
2. Generate $5,000,000.00 within 8 years, every 8 years consistently
3. Optimize NAE and agents for successful options trading

ALIGNED WITH LONG-TERM PLAN:
- Generates strategies aligned with tiered framework (Wheel â†’ Momentum â†’ Multi-leg â†’ AI)
- Focuses on PDT-compliant strategies (no same-day round trips)
- Learns patterns that contribute to compound growth toward $5M goal
- See: docs/NAE_LONG_TERM_PLAN.md for full strategy details
"""

import os
import datetime
import json
import random
import statistics
import time
import requests  # type: ignore
import hashlib
from typing import List, Dict, Any, Optional, TYPE_CHECKING
from dataclasses import dataclass
from enum import Enum

if TYPE_CHECKING:
    from tools.data.youtube_transcript_fetcher import ExtractedKnowledge

# Goals embedded - managed by GoalManager
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from goal_manager import get_nae_goals
GOALS = get_nae_goals()

# ----------------------
# Enums and Data Classes
# ----------------------
class DataSource(Enum):
    POLYGON = "polygon"
    QUANTCONNECT = "quantconnect"
    AI_SOURCE = "ai_source"
    WEB_SOURCE = "web_source"
    GITHUB = "github"

class BacktestStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"

@dataclass
class MarketDataPoint:
    """Market data point with timestamp and validation"""
    symbol: str
    timestamp: str
    open_price: float
    high_price: float
    low_price: float
    close_price: float
    volume: int
    source: str
    hash: str

@dataclass
class BacktestResult:
    """Comprehensive backtest result"""
    strategy_id: str
    start_date: str
    end_date: str
    total_return: float
    sharpe_ratio: float
    max_drawdown: float
    win_rate: float
    total_trades: int
    avg_trade_return: float
    volatility: float
    calmar_ratio: float
    status: BacktestStatus
    execution_time: float
    data_points: int

# ----------------------
# Market Data Integration
# ----------------------
class PolygonDataClient:
    """Enhanced Polygon.io client with rate limiting and error handling"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.polygon.io"
        self.rate_limit_remaining = 1000  # Polygon free tier limit
        self.last_request_time = 0
        self.request_count = 0
        self.daily_limit = 1000
        
    def _rate_limit_check(self):
        """Enforce rate limiting with exponential backoff"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        # Polygon free tier: 5 calls per minute
        if time_since_last < 12:  # 5 calls per minute = 12 seconds between calls
            time.sleep(12 - time_since_last)
        
        self.last_request_time = time.time()
        self.request_count += 1
        
        # Daily limit check
        if self.request_count >= self.daily_limit:
            raise Exception(f"Daily API limit reached: {self.daily_limit}")
    
    def get_real_time_price(self, symbol: str) -> Optional[float]:
        """Get real-time price with error handling"""
        try:
            self._rate_limit_check()
            url = f"{self.base_url}/v2/last/trade/{symbol}"
            params = {"apikey": self.api_key}
            
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                return data.get("results", {}).get("p", 0)
            else:
                print(f"Polygon API error: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"Error getting real-time price for {symbol}: {e}")
            return None
    
    def get_historical_data(self, symbol: str, start_date: str, end_date: str, 
                          timespan: str = "day") -> List[MarketDataPoint]:
        """Get historical data with validation and hashing"""
        try:
            self._rate_limit_check()
            url = f"{self.base_url}/v2/aggs/ticker/{symbol}/range/1/{timespan}/{start_date}/{end_date}"
            params = {"apikey": self.api_key}
            
            response = requests.get(url, params=params, timeout=15)
            if response.status_code == 200:
                data = response.json()
                results = data.get("results", [])
                
                market_data = []
                for item in results:
                    # Create hash for data integrity
                    data_string = f"{symbol}{item['t']}{item['o']}{item['h']}{item['l']}{item['c']}{item['v']}"
                    data_hash = hashlib.sha256(data_string.encode()).hexdigest()
                    
                    market_data.append(MarketDataPoint(
                        symbol=symbol,
                        timestamp=datetime.datetime.fromtimestamp(item['t'] / 1000).isoformat(),
                        open_price=item['o'],
                        high_price=item['h'],
                        low_price=item['l'],
                        close_price=item['c'],
                        volume=item['v'],
                        source="polygon",
                        hash=data_hash
                    ))
                
                return market_data
            else:
                print(f"Polygon historical data error: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"Error getting historical data for {symbol}: {e}")
            return []
    
    def get_market_status(self) -> Dict[str, Any]:
        """Get market status and trading hours"""
        try:
            self._rate_limit_check()
            url = f"{self.base_url}/v1/marketstatus/now"
            params = {"apikey": self.api_key}
            
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                return response.json()
            else:
                return {"status": "unknown", "error": response.status_code}
                
        except Exception as e:
            print(f"Error getting market status: {e}")
            return {"status": "error", "error": str(e)}

# ----------------------
# QuantConnect Integration
# ----------------------
class QuantConnectClient:
    """QuantConnect API client for backtesting and live deployment"""
    
    def __init__(self, user_id: str, api_key: str):
        self.user_id = user_id
        self.api_key = api_key
        self.base_url = "https://www.quantconnect.com/api/v2"
        self.rate_limit_remaining = 100
        self.last_request_time = 0
        
    def _rate_limit_check(self):
        """Enforce QuantConnect rate limiting"""
        current_time = time.time()
        if current_time - self.last_request_time < 1:  # 1 second between requests
            time.sleep(1 - (current_time - self.last_request_time))
        self.last_request_time = time.time()
    
    def create_backtest(self, strategy_code: str, strategy_name: str, 
                       start_date: str, end_date: str, 
                       initial_capital: float = 100000) -> Dict[str, Any]:
        """Create and run a backtest on QuantConnect"""
        try:
            self._rate_limit_check()
            
            # Prepare backtest parameters
            backtest_params = {
                "name": strategy_name,
                "code": strategy_code,
                "startDate": start_date,
                "endDate": end_date,
                "initialCapital": initial_capital,
                "language": "Python"
            }
            
            # This would integrate with actual QuantConnect API
            # For now, return a simulated result
            return {
                "backtest_id": f"qc_{int(time.time())}",
                "status": "submitted",
                "estimated_runtime": "5-10 minutes",
                "parameters": backtest_params
            }
            
        except Exception as e:
            return {"error": f"QuantConnect backtest creation failed: {e}"}
    
    def get_backtest_results(self, backtest_id: str) -> Optional[BacktestResult]:
        """Retrieve backtest results from QuantConnect"""
        try:
            self._rate_limit_check()
            
            # Simulate backtest results (replace with actual API call)
            return BacktestResult(
                strategy_id=backtest_id,
                start_date="2023-01-01",
                end_date="2023-12-31",
                total_return=0.15,
                sharpe_ratio=1.2,
                max_drawdown=0.08,
                win_rate=0.65,
                total_trades=150,
                avg_trade_return=0.001,
                volatility=0.12,
                calmar_ratio=1.875,
                status=BacktestStatus.COMPLETED,
                execution_time=300.0,
                data_points=252
            )
            
        except Exception as e:
            print(f"Error retrieving backtest results: {e}")
            return None
    
    def deploy_strategy(self, strategy_code: str, strategy_name: str, 
                       paper_trading: bool = True) -> Dict[str, Any]:
        """Deploy strategy to live/paper trading"""
        try:
            self._rate_limit_check()
            
            deployment_params = {
                "name": strategy_name,
                "code": strategy_code,
                "paper_trading": paper_trading,
                "language": "Python"
            }
            
            return {
                "deployment_id": f"deploy_{int(time.time())}",
                "status": "deployed",
                "paper_trading": paper_trading,
                "parameters": deployment_params
            }
            
        except Exception as e:
            return {"error": f"Strategy deployment failed: {e}"}

# ----------------------
# GitHub Integration Client
# ----------------------
class GitHubClient:
    """GitHub API client for discovering trading algorithms, tools, and strategies"""
    
    def __init__(self, api_token: Optional[str] = None):
        """
        Initialize GitHub client
        
        Args:
            api_token: GitHub personal access token (optional, but recommended for rate limits)
        """
        self.api_token = api_token or os.getenv('GITHUB_TOKEN', '')
        self.base_url = "https://api.github.com"
        self.rate_limit_remaining = 60
        self.last_request_time = 0
        self.headers = {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "NAE-Ralph-Agent"
        }
        if self.api_token:
            # Use "Bearer" for fine-grained PATs (github_pat_*) and "token" for classic tokens
            if self.api_token.startswith('github_pat_'):
                self.headers["Authorization"] = f"Bearer {self.api_token}"
            else:
                self.headers["Authorization"] = f"token {self.api_token}"
            self.rate_limit_remaining = 5000  # Authenticated requests have higher limits
    
    def _rate_limit_check(self):
        """Enforce GitHub rate limiting"""
        current_time = time.time()
        if current_time - self.last_request_time < 0.1:  # 10 requests per second
            time.sleep(0.1 - (current_time - self.last_request_time))
        self.last_request_time = time.time()
    
    def search_repositories(self, query: str, sort: str = "stars", order: str = "desc", 
                           per_page: int = 10) -> List[Dict[str, Any]]:
        """
        Search GitHub repositories
        
        Args:
            query: Search query (e.g., "trading strategy python options")
            sort: Sort by "stars", "forks", "updated", etc.
            order: "asc" or "desc"
            per_page: Number of results per page (max 100)
        
        Returns:
            List of repository information dictionaries
        """
        try:
            self._rate_limit_check()
            
            url = f"{self.base_url}/search/repositories"
            params = {
                "q": query,
                "sort": sort,
                "order": order,
                "per_page": min(per_page, 100)
            }
            
            response = requests.get(url, headers=self.headers, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            self.rate_limit_remaining = int(response.headers.get('X-RateLimit-Remaining', 0))
            
            return data.get("items", [])
            
        except Exception as e:
            print(f"Error searching GitHub repositories: {e}")
            return []
    
    def get_repository_content(self, owner: str, repo: str, path: str = "") -> Optional[Dict[str, Any]]:
        """
        Get repository content (files, code, etc.)
        
        Args:
            owner: Repository owner
            repo: Repository name
            path: Path within repository (empty for root)
        
        Returns:
            Repository content information
        """
        try:
            self._rate_limit_check()
            
            url = f"{self.base_url}/repos/{owner}/{repo}/contents/{path}"
            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            self.rate_limit_remaining = int(response.headers.get('X-RateLimit-Remaining', 0))
            return response.json()
            
        except Exception as e:
            print(f"Error getting repository content: {e}")
            return None
    
    def get_file_content(self, owner: str, repo: str, path: str) -> Optional[str]:
        """
        Get raw file content from repository
        
        Args:
            owner: Repository owner
            repo: Repository name
            path: Path to file
        
        Returns:
            File content as string
        """
        try:
            self._rate_limit_check()
            
            url = f"{self.base_url}/repos/{owner}/{repo}/contents/{path}"
            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            if data.get("encoding") == "base64":
                import base64
                return base64.b64decode(data["content"]).decode('utf-8')
            
            return None
            
        except Exception as e:
            print(f"Error getting file content: {e}")
            return None

# VERY_AGGRESSIVE configuration for faster strategy generation
# Optimized for $6.2M target / $15.7M stretch goal
DEFAULT_CONFIG = {
    "min_trust_score": 45.0,      # AGGRESSIVE: Lower threshold (was 55.0) for more strategies
    "min_backtest_score": 25.0,   # AGGRESSIVE: Lower (was 30.0) - let more strategies through
    "min_consensus_sources": 1,   # Keep at 1 for maximum strategy throughput
    "max_drawdown_pct": 0.70,     # AGGRESSIVE: Accept higher drawdown (was 0.6)
    "source_reputations": {       # baseline reputation weights (can be expanded)
        "Grok": 85,
        "DeepSeek": 80,
        "Claude": 82,
        "toptrader.com": 75,
        "optionsforum.com": 60,
        "financeapi.local": 70,
        "youtube": 50  # Base YouTube reputation (can be boosted by trusted channels)
    },
    "youtube_video_urls": [],  # List of YouTube video URLs/IDs to process
    "youtube_trusted_channels": [],  # List of trusted YouTube channel names (case-insensitive)
    # VERY_AGGRESSIVE: Prioritize high-growth strategies
    "priority_strategies": [
        "momentum", "breakout", "0dte", "earnings", "leveraged_etf",
        "high_growth", "swing", "trend_following"
    ],
    "growth_milestones": {
        1: 9_411, 2: 44_110, 3: 152_834, 4: 388_657,
        5: 982_500, 6: 2_477_897, 7: 6_243_561, 8: 15_726_144
    }
}

class RalphAgent:
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.goals = GOALS  # 3 Core Goals: Generational wealth, $5M in 8 years, Optimize options trading
        self.long_term_plan = "docs/NAE_LONG_TERM_PLAN.md"  # Reference to long-term plan
        self.target_goal = 5000000.0  # $5M goal from Goal #2
        self.accelerator_enabled = True  # ALWAYS ON - support Optimus accelerator strategy infinitely
        self.config = DEFAULT_CONFIG.copy()
        if config:
            self.config.update(config)
        
        # ----------------------
        # Logging and Data Storage
        # ----------------------
        self.log_file = "logs/ralph.log"
        self.audit_log_file = "logs/ralph_audit.log"
        os.makedirs(os.path.dirname(self.log_file), exist_ok=True)
        
        # ----------------------
        # Strategy Management
        # ----------------------
        self.strategy_database: List[Dict[str, Any]] = []  # approved strategies
        self.candidate_pool: List[Dict[str, Any]] = []     # raw candidates
        self.backtest_results: List[BacktestResult] = []    # QuantConnect backtest results
        self.market_data_cache: Dict[str, List[MarketDataPoint]] = {}  # Cached market data
        self.status: str = "Idle"
        
        # ----------------------
        # External API Clients
        # ----------------------
        self.polygon_client = None
        self.quantconnect_client = None
        self.github_client = None  # Initialize as None, will be set in _initialize_api_clients
        self._initialize_api_clients()
        
        # ----------------------
        # Profit Enhancement: LSTM Price Predictor
        # ----------------------
        try:
            from tools.profit_algorithms import LSTMPredictor
            self.lstm_predictor = LSTMPredictor()
            self.lstm_predictor.load_model()  # Try to load existing model
        except ImportError:
            self.lstm_predictor = None
            self.log_action("LSTM predictor not available (TensorFlow may not be installed)")
        
        # ----------------------
        # THRML Energy-Based Learning for Strategy Patterns
        # ----------------------
        try:
            from tools.thrml_integration import EnergyBasedStrategyModel
            try:
                import jax.numpy as jnp  # type: ignore
            except ImportError:
                jnp = None  # JAX not available, THRML will use fallback
            
            # Initialize EBM for strategy pattern recognition
            # Feature dimension: strategy characteristics (backtest_score, trust_score, sharpe, etc.)
            feature_dim = 10  # Adjust based on strategy feature space
            self.thrml_ebm = EnergyBasedStrategyModel(feature_dim=feature_dim)
            self.thrml_ebm.build_energy_function()
            
            self.thrml_enabled = True
            self.log_action("THRML energy-based strategy model initialized")
        except ImportError as e:
            self.thrml_ebm = None
            self.thrml_enabled = False
            self.log_action(f"THRML not available: {e}. Install JAX and THRML for energy-based learning.")
        except Exception as e:
            self.thrml_ebm = None
            self.thrml_enabled = False
            self.log_action(f"THRML initialization failed: {e}")
        
        # ----------------------
        # Online Learning Framework
        # ----------------------
        try:
            from tools.online_learning import OnlineLearner, MetaLearner
            
            # Initialize online learner (will wrap EBM or other models)
            class StrategyModel:
                def __init__(self):
                    self.params = {}
                
                def get_parameters(self):
                    return self.params
            
            model = StrategyModel()
            self.online_learner = OnlineLearner(
                model=model,
                learning_rate=0.001,
                use_ewc=True,
                use_replay=True
            )
            self.meta_learner = MetaLearner()
            self.online_learning_enabled = True
            self.log_action("âœ… Online learning framework initialized")
        except Exception as e:
            self.online_learner = None
            self.meta_learner = None
            self.online_learning_enabled = False
            self.log_action(f"âš ï¸  Online learning not available: {e}")
        
        # ----------------------
        # Audit Logging
        # ----------------------
        self.audit_log = []
        
        # ----------------------
        # Improvement Metrics Tracking
        # ----------------------
        self.improvement_metrics = {
            "strategies_generated": 0,
            "strategies_approved": 0,
            "strategies_sent_to_optimus": 0,
            "github_discoveries": 0,
            "github_discoveries_sent_to_donnie": 0,
            "cycle_count": 0,
            "quality_score_history": [],
            "approval_rate_history": [],
            "last_improvement_check": None,
            "metrics_start_time": datetime.datetime.now()
        }
        
        # ----------------------
        # Messaging / AutoGen hooks
        # ----------------------
        self.inbox = []
        self.outbox = []
        
        # ----------------------
        # Direct Optimus Communication Channel
        # ----------------------
        self.optimus_direct_channel = None  # Will be set when Optimus is available
        
    def register_optimus_channel(self, optimus_agent):
        """
        Register Optimus agent for direct strategy communication
        
        This allows Ralph to send high-confidence strategies directly to Optimus
        without going through Donnie, enabling faster execution of proven strategies.
        
        Args:
            optimus_agent: OptimusAgent instance
        """
        self.optimus_direct_channel = optimus_agent
        self.log_action("âœ… Direct Optimus communication channel registered")
        
        # ----------------------
        # Excellence Protocol
        # ----------------------
        self.excellence_protocol = None
        try:
            from agents.ralph_excellence_protocol import RalphExcellenceProtocol
            self.excellence_protocol = RalphExcellenceProtocol(self)
            self.excellence_protocol.start_excellence_mode()
            self.log_action("ðŸŽ¯ Ralph Excellence Protocol initialized and active - Continuous improvement, learning, self-awareness, and self-healing enabled")
        except ImportError as e:
            self.log_action(f"âš ï¸ Excellence protocol not available: {e}")
        except Exception as e:
            self.log_action(f"âš ï¸ Excellence protocol initialization failed: {e}")
        
        self.log_action("RalphAgent v4 initialized with market data and QuantConnect integration")

    # ----------------------
    # API Client Initialization
    # ----------------------
    def _initialize_api_clients(self):
        """Initialize external API clients"""
        try:
            # Initialize Polygon client (placeholder for API key)
            polygon_key = os.getenv('POLYGON_API_KEY', 'demo_key')
            
            # Also try to load from config file
            if polygon_key == 'demo_key':
                try:
                    with open('config/api_keys.json', 'r') as f:
                        api_config = json.load(f)
                        if 'polygon' in api_config and api_config['polygon'].get('api_key'):
                            polygon_key = api_config['polygon']['api_key']
                except Exception:  # Config file may not exist, continue with env var
                    pass
            
            if polygon_key and polygon_key != 'demo_key':
                self.polygon_client = PolygonDataClient(polygon_key)
                self.log_action("Polygon data client initialized")
            else:
                self.log_action("Polygon API key not configured - using demo mode")
            
            # Initialize QuantConnect client (placeholder for credentials)
            qc_user_id = os.getenv('QUANTCONNECT_USER_ID', 'demo_user')
            qc_api_key = os.getenv('QUANTCONNECT_API_KEY', 'demo_key')
            if qc_user_id != 'demo_user' and qc_api_key != 'demo_key':
                self.quantconnect_client = QuantConnectClient(qc_user_id, qc_api_key)
                self.log_action("QuantConnect client initialized")
            else:
                self.log_action("QuantConnect credentials not configured - using demo mode")
            
            # Initialize GitHub client
            github_token = os.getenv('GITHUB_TOKEN', '')
            if not github_token:
                # Try to load from config file (resolve path relative to NAE Ready directory)
                try:
                    # Get the directory of this file (agents/)
                    current_dir = os.path.dirname(os.path.abspath(__file__))
                    # Go up one level to NAE Ready/, then to config/
                    nae_dir = os.path.dirname(current_dir)
                    api_keys_path = os.path.join(nae_dir, 'config', 'api_keys.json')
                    
                    if os.path.exists(api_keys_path):
                        with open(api_keys_path, 'r') as f:
                            api_config = json.load(f)
                            if 'github' in api_config and api_config['github'].get('api_token'):
                                github_token = api_config['github']['api_token']
                except Exception as e:
                    # Silently fail - will use no token
                    pass
            
            # Initialize GitHub client (always initialize, even without token)
            try:
                self.github_client = GitHubClient(api_token=github_token if github_token else None)
                if github_token:
                    self.log_action("âœ… GitHub client initialized with authentication (5000 req/hr)")
                else:
                    self.log_action("âš ï¸ GitHub client initialized without authentication (rate limits: 60 req/hr)")
            except Exception as e:
                self.github_client = None
                self.log_action(f"âš ï¸ GitHub client initialization failed: {e}")
                
        except Exception as e:
            self.log_action(f"Error initializing API clients: {e}")

    # ----------------------
    # Market Data Integration
    # ----------------------
    def fetch_market_data(self, symbol: str, start_date: str, end_date: str, 
                         timespan: str = "day") -> List[MarketDataPoint]:
        """Fetch market data with caching and validation"""
        try:
            cache_key = f"{symbol}_{start_date}_{end_date}_{timespan}"
            
            # Check cache first
            if cache_key in self.market_data_cache:
                self.log_action(f"Using cached market data for {symbol}")
                return self.market_data_cache[cache_key]
            
            # Fetch from Polygon if available
            if self.polygon_client:
                market_data = self.polygon_client.get_historical_data(symbol, start_date, end_date, timespan)
                if market_data:
                    self.market_data_cache[cache_key] = market_data
                    self._create_audit_log("MARKET_DATA_FETCHED", {
                        "symbol": symbol,
                        "start_date": start_date,
                        "end_date": end_date,
                        "data_points": len(market_data),
                        "source": "polygon"
                    })
                    self.log_action(f"Fetched {len(market_data)} data points for {symbol}")
                    return market_data
            
            # Fallback to simulated data
            self.log_action(f"Using simulated market data for {symbol}")
            return self._generate_simulated_market_data(symbol, start_date, end_date)
            
        except Exception as e:
            self.log_action(f"Error fetching market data for {symbol}: {e}")
            return []

    def _generate_simulated_market_data(self, symbol: str, start_date: str, end_date: str) -> List[MarketDataPoint]:
        """Generate simulated market data for testing"""
        import random
        from datetime import datetime, timedelta
        
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        
        market_data = []
        current_price = 100.0  # Starting price
        
        current_date = start_dt
        while current_date <= end_dt:
            # Simulate price movement
            daily_return = random.gauss(0.001, 0.02)  # 0.1% mean return, 2% volatility
            current_price *= (1 + daily_return)
            
            # Generate OHLC data
            high = current_price * (1 + abs(random.gauss(0, 0.01)))
            low = current_price * (1 - abs(random.gauss(0, 0.01)))
            volume = random.randint(1000000, 5000000)
            
            data_string = f"{symbol}{current_date.timestamp()}{current_price}{high}{low}{current_price}{volume}"
            data_hash = hashlib.sha256(data_string.encode()).hexdigest()
            
            market_data.append(MarketDataPoint(
                symbol=symbol,
                timestamp=current_date.isoformat(),
                open_price=current_price,
                high_price=high,
                low_price=low,
                close_price=current_price,
                volume=volume,
                source="simulated",
                hash=data_hash
            ))
            
            current_date += timedelta(days=1)
        
        return market_data

    def get_real_time_price(self, symbol: str) -> Optional[float]:
        """Get real-time price for a symbol"""
        try:
            if self.polygon_client:
                price = self.polygon_client.get_real_time_price(symbol)
                if price:
                    self._create_audit_log("REAL_TIME_PRICE_FETCHED", {
                        "symbol": symbol,
                        "price": price,
                        "source": "polygon"
                    })
                    return price
            
            # Fallback to simulated price
            return random.uniform(50, 200)
            
        except Exception as e:
            self.log_action(f"Error getting real-time price for {symbol}: {e}")
            return None
    
    def get_intraday_direction_probability(self, symbol: str) -> Dict[str, float]:
        """
        Get intraday direction probability for a symbol.
        
        This method analyzes recent market data and provides probability estimates
        for upward and downward moves. Used by Optimus accelerator strategy.
        
        Args:
            symbol: Symbol to analyze (e.g., "SPY")
        
        Returns:
            Dictionary with:
                - prob_up: Probability of upward move (0.0-1.0)
                - prob_down: Probability of downward move (0.0-1.0)
                - confidence: Overall confidence in prediction (0.0-1.0)
        """
        try:
            # Get recent market data (last 5 days)
            end_date = datetime.datetime.now().strftime("%Y-%m-%d")
            start_date = (datetime.datetime.now() - datetime.timedelta(days=5)).strftime("%Y-%m-%d")
            
            market_data = self.fetch_market_data(symbol, start_date, end_date, timespan="day")
            
            if not market_data:
                # Fallback: neutral probabilities
                return {
                    "prob_up": 0.5,
                    "prob_down": 0.5,
                    "confidence": 0.0
                }
            
            # Analyze recent price action
            closes = [d.close_price for d in market_data[-5:]]
            if len(closes) < 2:
                return {
                    "prob_up": 0.5,
                    "prob_down": 0.5,
                    "confidence": 0.0
                }
            
            # Simple momentum-based probability
            recent_change = (closes[-1] - closes[0]) / closes[0] if closes[0] > 0 else 0.0
            
            # Calculate probabilities based on momentum
            # Positive momentum -> higher prob_up
            # Negative momentum -> higher prob_down
            
            # Base probabilities
            prob_up = 0.5
            prob_down = 0.5
            
            # Adjust based on momentum
            if recent_change > 0.01:  # 1% positive move
                prob_up = min(0.85, 0.5 + abs(recent_change) * 10)
                prob_down = 1.0 - prob_up
            elif recent_change < -0.01:  # 1% negative move
                prob_down = min(0.85, 0.5 + abs(recent_change) * 10)
                prob_up = 1.0 - prob_down
            
            # Confidence based on data quality and signal strength
            confidence = min(0.9, abs(recent_change) * 20) if abs(recent_change) > 0.005 else 0.3
            
            # Use LSTM predictor if available for enhanced signal
            if self.lstm_predictor:
                try:
                    # Get price data for LSTM prediction
                    price_data = [d.close_price for d in market_data[-60:]]  # Last 60 prices
                    if len(price_data) >= 10:
                        # Get LSTM prediction (returns predicted price)
                        lstm_pred_price = self.lstm_predictor.predict(price_data)
                        if lstm_pred_price is not None and len(closes) > 0:
                            current_price = closes[-1]
                            # Determine direction based on predicted vs current price
                            price_change = (lstm_pred_price - current_price) / current_price if current_price > 0 else 0
                            
                            # Calculate confidence based on magnitude of predicted change
                            lstm_confidence = min(0.9, abs(price_change) * 10)
                            
                            if price_change > 0.005:  # Predicting up
                                prob_up = (prob_up * 0.6 + lstm_confidence * 0.4)
                                prob_down = 1.0 - prob_up
                            elif price_change < -0.005:  # Predicting down
                                prob_down = (prob_down * 0.6 + lstm_confidence * 0.4)
                                prob_up = 1.0 - prob_down
                            
                            confidence = max(confidence, lstm_confidence * 0.8)
                except Exception as e:
                    self.log_action(f"LSTM prediction error: {e}")
            
            # Ensure probabilities sum to 1.0
            total = prob_up + prob_down
            if total > 0:
                prob_up = prob_up / total
                prob_down = prob_down / total
            
            return {
                "prob_up": max(0.0, min(1.0, prob_up)),
                "prob_down": max(0.0, min(1.0, prob_down)),
                "confidence": max(0.0, min(1.0, confidence))
            }
            
        except Exception as e:
            self.log_action(f"Error getting intraday direction probability for {symbol}: {e}")
            # Return neutral probabilities on error
            return {
                "prob_up": 0.5,
                "prob_down": 0.5,
                "confidence": 0.0
            }
    
    def retrain_hook(self, summary: Dict[str, Any]) -> None:
        """
        Retrain hook for session-based learning.
        
        Called by accelerator strategy to feed recent trade results back
        into Ralph for quick model adjustments.
        
        Args:
            summary: Dictionary with trade results and account info:
                - trades: List of recent trade results
                - account_balance: Current account balance
                - timestamp: Timestamp of summary
                - daily_profit: Daily profit/loss
        """
        try:
            trades = summary.get("trades", [])
            if not trades:
                return
            
            # Log retrain request
            self.log_action(f"Retrain hook called with {len(trades)} trades")
            
            # Extract patterns from trades
            wins = [t for t in trades if t.get("result") == "win"]
            losses = [t for t in trades if t.get("result") == "loss"]
            
            win_rate = len(wins) / len(trades) if trades else 0.0
            
            # Update strategy database with new performance data
            # This is a lightweight update - not full model retrain
            if win_rate > 0.6:
                self.log_action(f"Good performance detected (win_rate: {win_rate:.2%}), "
                              f"considering strategy adjustments")
            elif win_rate < 0.4:
                self.log_action(f"Poor performance detected (win_rate: {win_rate:.2%}), "
                              f"may need to adjust signal thresholds")
            
            # If online learning is enabled, update model
            if self.online_learning_enabled and self.online_learner:
                try:
                    # Create training example from trades
                    # This is simplified - real implementation would extract features
                    self.log_action("Online learning update triggered")
                except Exception as e:
                    self.log_action(f"Online learning update error: {e}")
            
        except Exception as e:
            self.log_action(f"Error in retrain hook: {e}")

    # ----------------------
    # Enhanced Backtesting with QuantConnect
    # ----------------------
    def run_quantconnect_backtest(self, strategy_code: str, strategy_name: str,
                                 start_date: str, end_date: str,
                                 initial_capital: float = 100000) -> Optional[BacktestResult]:
        """Run professional backtest using QuantConnect"""
        try:
            if not self.quantconnect_client:
                self.log_action("QuantConnect client not available - using simulated backtest")
                return self._run_simulated_backtest(strategy_name, start_date, end_date)
            
            # Create backtest on QuantConnect
            backtest_response = self.quantconnect_client.create_backtest(
                strategy_code, strategy_name, start_date, end_date, initial_capital
            )
            
            if "error" in backtest_response:
                self.log_action(f"QuantConnect backtest failed: {backtest_response['error']}")
                return None
            
            backtest_id = backtest_response["backtest_id"]
            self.log_action(f"QuantConnect backtest submitted: {backtest_id}")
            
            # Wait for completion (in production, this would be async)
            time.sleep(2)  # Simulate wait time
            
            # Retrieve results
            result = self.quantconnect_client.get_backtest_results(backtest_id)
            if result:
                self.backtest_results.append(result)
                self._create_audit_log("QUANTCONNECT_BACKTEST_COMPLETED", {
                    "strategy_name": strategy_name,
                    "backtest_id": backtest_id,
                    "total_return": result.total_return,
                    "sharpe_ratio": result.sharpe_ratio,
                    "max_drawdown": result.max_drawdown
                })
                self.log_action(f"QuantConnect backtest completed: {result.total_return:.2%} return")
            
            return result
            
        except Exception as e:
            self.log_action(f"Error running QuantConnect backtest: {e}")
            return None

    def _run_simulated_backtest(self, strategy_name: str, start_date: str, end_date: str) -> BacktestResult:
        """Run simulated backtest for testing purposes"""
        # Simulate backtest results
        total_return = random.uniform(-0.2, 0.3)  # -20% to +30% return
        sharpe_ratio = random.uniform(0.5, 2.0)
        max_drawdown = random.uniform(0.05, 0.25)
        win_rate = random.uniform(0.4, 0.8)
        total_trades = random.randint(50, 300)
        
        result = BacktestResult(
            strategy_id=f"sim_{int(time.time())}",
            start_date=start_date,
            end_date=end_date,
            total_return=total_return,
            sharpe_ratio=sharpe_ratio,
            max_drawdown=max_drawdown,
            win_rate=win_rate,
            total_trades=total_trades,
            avg_trade_return=total_return / total_trades,
            volatility=random.uniform(0.1, 0.3),
            calmar_ratio=total_return / max_drawdown if max_drawdown > 0 else 0,
            status=BacktestStatus.COMPLETED,
            execution_time=random.uniform(10, 60),
            data_points=random.randint(100, 500)
        )
        
        self.backtest_results.append(result)
        return result

    # ----------------------
    # Audit Logging
    # ----------------------
    def _create_audit_log(self, action: str, details: Dict[str, Any], user_id: str = "system") -> str:
        """Create immutable audit log entry"""
        timestamp = datetime.datetime.now().isoformat()
        
        # Create hash of the log entry for integrity
        log_data = {
            "timestamp": timestamp,
            "action": action,
            "details": details,
            "user_id": user_id
        }
        
        log_string = json.dumps(log_data, sort_keys=True)
        log_hash = hashlib.sha256(log_string.encode()).hexdigest()
        
        # Store in memory and file
        self.audit_log.append({
            "timestamp": timestamp,
            "action": action,
            "details": details,
            "hash": log_hash,
            "user_id": user_id
        })
        
        # Write to immutable audit log file
        try:
            with open(self.audit_log_file, "a") as f:
                f.write(f"{log_string}|{log_hash}\n")
        except Exception as e:
            self.log_action(f"Error writing audit log: {e}")
        
        return log_hash

    # ----------------------
    # Logging
    # ----------------------
    def log_action(self, message: str):
        ts = datetime.datetime.now().isoformat()
        with open(self.log_file, "a") as f:
            f.write(f"[{ts}] {message}\n")
        print(f"[Ralph LOG] {message}")

    # ----------------------
    # GitHub Ingestion - Discover tools, algorithms, and strategies
    # ----------------------
    def ingest_from_github(self, search_queries: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        Discover useful trading tools, algorithms, and strategies from GitHub
        
        Searches GitHub for open-source trading algorithms, tools, and strategies
        that can enhance NAE's capabilities. These discoveries are sent to Donnie
        for implementation.
        
        Args:
            search_queries: List of search queries (default: common trading-related queries)
        
        Returns:
            List of discovered repositories/tools formatted for processing
        """
        if search_queries is None:
            search_queries = [
                "options trading strategy python",
                "algorithmic trading python",
                "quantconnect strategy",
                "backtesting framework python",
                "trading indicators python",
                "market data analysis python",
                "risk management trading",
                "portfolio optimization python",
                "technical analysis library python",
                "trading bot framework"
            ]
        
        results = []
        
        if not hasattr(self, 'github_client') or not self.github_client:
            self.log_action("âš ï¸ GitHub client not available for ingestion")
            return results
        
        try:
            for query in search_queries[:5]:  # Limit to 5 queries per cycle
                self.log_action(f"Searching GitHub for: {query}")
                
                repos = self.github_client.search_repositories(
                    query=query,
                    sort="stars",
                    order="desc",
                    per_page=10
                )
                
                for repo in repos:
                    # Extract useful information
                    repo_info = {
                        "id": f"github_{repo['full_name'].replace('/', '_')}",
                        "name": repo.get('name', 'Unknown'),
                        "full_name": repo.get('full_name', ''),
                        "source": DataSource.GITHUB.value,
                        "details": repo.get('description', ''),
                        "url": repo.get('html_url', ''),
                        "stars": repo.get('stargazers_count', 0),
                        "forks": repo.get('forks_count', 0),
                        "language": repo.get('language', ''),
                        "topics": repo.get('topics', []),
                        "updated_at": repo.get('updated_at', ''),
                        "raw_score": min(1.0, (repo.get('stargazers_count', 0) / 1000.0) * 0.5 + 0.5),
                        "type": "tool" if "tool" in query.lower() or "framework" in query.lower() else "strategy",
                        "metadata": {
                            "owner": repo.get('owner', {}).get('login', ''),
                            "license": repo.get('license', {}).get('name', '') if repo.get('license') else None,
                            "size": repo.get('size', 0),
                            "has_issues": repo.get('has_issues', False),
                            "has_wiki": repo.get('has_wiki', False)
                        }
                    }
                    
                    results.append(repo_info)
            
            self.log_action(f"âœ… Ingested {len(results)} items from GitHub repositories")
            
        except Exception as e:
            self.log_action(f"Error ingesting from GitHub: {e}")
            import traceback
            self.log_action(traceback.format_exc())
        
        return results
    
    # ----------------------
    # Placeholder: ingest from AI sources (Grok, DeepSeek, Claude)
    # ----------------------
    def ingest_from_ai_sources(self) -> List[Dict[str, Any]]:
        sources = ["Grok", "DeepSeek", "Claude"]
        results = []
        for src in sources:
            for i in range(2):
                results.append({
                    "id": f"{src}_insight_{i+1}",
                    "name": f"{src} Insight {i+1}",
                    "source": src,
                    "details": f"AI-generated signal from {src}, variant {i+1}",
                    "raw_score": random.uniform(0.4, 0.95)
                })
        self.log_action(f"Ingested {len(results)} items from AI sources")
        return results

    # ----------------------
    # Placeholder: ingest from web/top traders/forums
    # ----------------------
    def ingest_from_web_sources(self, urls: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        if urls is None:
            urls = ["toptrader.com", "optionsforum.com", "twitter:top_traders_feed", "reddit:options"]
        results = []
        for src in urls:
            for i in range(random.randint(1, 3)):
                results.append({
                    "id": f"{src}_post_{i+1}",
                    "name": f"{src} Strategy {i+1}",
                    "source": src,
                    "details": f"Scraped strategy from {src}, post {i+1}",
                    "raw_score": random.uniform(0.2, 0.9)
                })
        self.log_action(f"Ingested {len(results)} items from web sources ({len(urls)} sources)")
        return results

    # ----------------------
    # YouTube Transcript Ingestion
    # ----------------------
    def ingest_from_youtube(self, video_urls: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        Fetch YouTube transcripts and extract trading knowledge
        
        This is part of Ralph's automatic learning process.
        YouTube videos often contain opinions, not truth, so strategies are:
        - Cross-checked with performance data
        - Compared with existing strategies
        - Filtered for high-probability strategies only
        - Flagged for hype/risk
        
        Args:
            video_urls: List of YouTube video URLs or video IDs. If None, uses configured list.
            
        Returns:
            List of strategy candidates extracted from YouTube videos
        """
        try:
            from tools.data.youtube_transcript_fetcher import YouTubeTranscriptFetcher, ExtractedKnowledge
            
            if video_urls is None:
                # Use configured YouTube video list (can be set via config)
                video_urls = self.config.get("youtube_video_urls", [])
            
            if not video_urls:
                self.log_action("No YouTube URLs configured - skipping YouTube ingestion")
                return []
            
            fetcher = YouTubeTranscriptFetcher()
            results = []
            
            self.log_action(f"Starting YouTube transcript ingestion from {len(video_urls)} videos")
            
            # Fetch transcripts
            video_infos = fetcher.fetch_multiple_transcripts(video_urls)
            
            if not video_infos:
                self.log_action("No transcripts fetched from YouTube videos")
                fetcher.cleanup()
                return []
            
            self.log_action(f"Successfully fetched {len(video_infos)} transcripts")
            
            # Process each video
            for video_info in video_infos:
                try:
                    # Extract knowledge from transcript
                    knowledge = fetcher.extract_knowledge(video_info)
                    
                    # Convert extracted knowledge to strategy candidates
                    candidates = self._convert_youtube_knowledge_to_candidates(knowledge, video_info)
                    
                    # Cross-check strategies with performance data
                    validated_candidates = self._cross_check_youtube_strategies(candidates)
                    
                    # Filter out low-quality/hype strategies
                    filtered_candidates = self._filter_youtube_strategies(validated_candidates)
                    
                    results.extend(filtered_candidates)
                    
                    self.log_action(
                        f"Processed video '{video_info.title}': "
                        f"{len(knowledge.strategies)} strategies, "
                        f"{len(filtered_candidates)} passed validation"
                    )
                    
                except Exception as e:
                    self.log_action(f"Error processing video {video_info.video_id}: {e}")
                    continue
            
            fetcher.cleanup()
            self.log_action(f"YouTube ingestion complete: {len(results)} strategy candidates extracted")
            
            return results
            
        except ImportError as e:
            self.log_action(f"YouTube transcript fetcher not available: {e}")
            return []
        except Exception as e:
            self.log_action(f"Error in YouTube ingestion: {e}")
            return []
    
    def _convert_youtube_knowledge_to_candidates(
        self, 
        knowledge: 'ExtractedKnowledge', 
        video_info: Any
    ) -> List[Dict[str, Any]]:
        """
        Convert extracted YouTube knowledge to strategy candidate format
        
        Args:
            knowledge: ExtractedKnowledge object from YouTube transcript
            video_info: YouTubeVideoInfo object
            
        Returns:
            List of strategy candidates in Ralph's format
        """
        candidates = []
        
        # Convert strategies to candidates
        for strategy in knowledge.strategies:
            candidate = {
                "id": strategy["strategy_id"],
                "name": f"YouTube Strategy: {strategy.get('type', 'unknown').replace('_', ' ').title()}",
                "source": f"youtube:{video_info.channel}",
                "details": strategy["text"],
                "raw_score": strategy.get("confidence", 0.5),
                "youtube_video_id": knowledge.video_id,
                "youtube_video_title": knowledge.video_title,
                "youtube_channel": video_info.channel,
                "youtube_url": video_info.url,
                "strategy_type": strategy.get("type", "unknown"),
                "extraction_metadata": {
                    "definitions_count": len(knowledge.definitions),
                    "rules_count": len(knowledge.rules),
                    "examples_count": len(knowledge.examples),
                    "risk_warnings_count": len(knowledge.risk_warnings),
                    "quality_score": knowledge.quality_score
                }
            }
            candidates.append(candidate)
        
        # Also create candidates from rules (if they contain actionable strategies)
        for rule in knowledge.rules:
            rule_text = rule["text"].lower()
            # Only create candidate if rule mentions a strategy
            if any(keyword in rule_text for keyword in [
                'strategy', 'trade', 'option', 'call', 'put', 'spread',
                'buy', 'sell', 'enter', 'exit'
            ]):
                candidate = {
                    "id": rule["rule_id"],
                    "name": f"YouTube Rule: Trading Rule",
                    "source": f"youtube:{video_info.channel}",
                    "details": rule["text"],
                    "raw_score": rule.get("confidence", 0.5) * 0.8,  # Rules slightly lower score
                    "youtube_video_id": knowledge.video_id,
                    "youtube_video_title": knowledge.video_title,
                    "youtube_channel": video_info.channel,
                    "youtube_url": video_info.url,
                    "strategy_type": "rule_based",
                    "extraction_metadata": {
                        "is_rule": True,
                        "quality_score": knowledge.quality_score
                    }
                }
                candidates.append(candidate)
        
        return candidates
    
    def _cross_check_youtube_strategies(
        self, 
        candidates: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Cross-check YouTube strategies with performance data and existing strategies
        
        This addresses the fact that YouTube videos often contain opinions, not truth.
        Strategies are validated against:
        - Existing strategy database
        - Market performance data
        - Historical backtest results
        
        Args:
            candidates: List of strategy candidates from YouTube
            
        Returns:
            List of validated candidates with cross-check scores
        """
        validated = []
        
        for candidate in candidates:
            # Initialize cross-check score
            cross_check_score = 0.0
            cross_check_reasons = []
            
            # Check against existing strategy database
            strategy_text = candidate.get("details", "").lower()
            matching_strategies = [
                s for s in self.strategy_database
                if any(keyword in s.get("name", "").lower() or keyword in s.get("details", "").lower()
                      for keyword in strategy_text.split()[:5])  # Check first 5 words
            ]
            
            if matching_strategies:
                # Strategy exists in database - boost score
                avg_trust = sum(s.get("trust_score", 0) for s in matching_strategies) / len(matching_strategies)
                cross_check_score += min(avg_trust * 0.3, 30)
                cross_check_reasons.append(f"Matches {len(matching_strategies)} existing strategies")
            
            # Check for performance indicators in text
            performance_keywords = [
                'backtest', 'tested', 'proven', 'win rate', 'profit', 'return',
                'sharpe', 'drawdown', 'performance', 'results'
            ]
            has_performance_data = any(keyword in strategy_text for keyword in performance_keywords)
            
            if has_performance_data:
                cross_check_score += 10
                cross_check_reasons.append("Contains performance data")
            else:
                # Penalize strategies without performance data (opinion-based)
                cross_check_score -= 5
                cross_check_reasons.append("No performance data - opinion-based")
            
            # Check for risk management mentions
            risk_keywords = ['risk', 'stop loss', 'management', 'position size', 'allocation']
            has_risk_management = any(keyword in strategy_text for keyword in risk_keywords)
            
            if has_risk_management:
                cross_check_score += 10
                cross_check_reasons.append("Includes risk management")
            
            # Check for hype indicators (negative)
            hype_keywords = [
                'guaranteed', 'sure thing', 'can\'t lose', 'easy money',
                'get rich quick', 'secret', 'insider', 'guaranteed profit'
            ]
            has_hype = any(keyword in strategy_text for keyword in hype_keywords)
            
            if has_hype:
                cross_check_score -= 20
                cross_check_reasons.append("WARNING: Contains hype indicators")
                candidate["hype_flag"] = True
            
            # Update candidate with cross-check data
            candidate["cross_check_score"] = max(0, min(100, cross_check_score))
            candidate["cross_check_reasons"] = cross_check_reasons
            candidate["validated"] = cross_check_score >= 20  # Minimum threshold
            
            validated.append(candidate)
        
        return validated
    
    def _filter_youtube_strategies(
        self, 
        candidates: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Filter YouTube strategies to keep only high-probability ones
        
        Filters out:
        - Low cross-check scores
        - Hype/risky strategies
        - Strategies without sufficient validation
        
        Args:
            candidates: List of validated strategy candidates
            
        Returns:
            List of filtered candidates that passed quality checks
        """
        filtered = []
        
        for candidate in candidates:
            # Skip if not validated
            if not candidate.get("validated", False):
                self.log_action(
                    f"Filtering out YouTube strategy '{candidate.get('name', 'unknown')}': "
                    f"Failed validation (score: {candidate.get('cross_check_score', 0)})"
                )
                continue
            
            # Skip if flagged as hype
            if candidate.get("hype_flag", False):
                self.log_action(
                    f"Filtering out YouTube strategy '{candidate.get('name', 'unknown')}': "
                    "Contains hype indicators"
                )
                continue
            
            # Skip if cross-check score too low
            cross_check_score = candidate.get("cross_check_score", 0)
            if cross_check_score < 20:
                self.log_action(
                    f"Filtering out YouTube strategy '{candidate.get('name', 'unknown')}': "
                    f"Low cross-check score ({cross_check_score})"
                )
                continue
            
            # Check quality score from extraction metadata
            extraction_meta = candidate.get("extraction_metadata", {})
            quality_score = extraction_meta.get("quality_score", 0)
            
            if quality_score < 30:
                self.log_action(
                    f"Filtering out YouTube strategy '{candidate.get('name', 'unknown')}': "
                    f"Low quality score ({quality_score})"
                )
                continue
            
            # Check if strategy has risk warnings (good sign - shows awareness)
            risk_warnings_count = extraction_meta.get("risk_warnings_count", 0)
            if risk_warnings_count == 0:
                # No risk warnings might indicate incomplete or superficial content
                candidate["raw_score"] = candidate.get("raw_score", 0.5) * 0.9  # Slight penalty
            
            # Add YouTube source reputation
            channel = candidate.get("youtube_channel", "").lower()
            youtube_reputation = self.config.get("source_reputations", {}).get("youtube", 50)
            
            # Adjust reputation based on channel (can be configured)
            known_good_channels = self.config.get("youtube_trusted_channels", [])
            if any(good_channel.lower() in channel for good_channel in known_good_channels):
                youtube_reputation = min(youtube_reputation + 20, 100)
            
            candidate["youtube_reputation"] = youtube_reputation
            
            filtered.append(candidate)
        
        self.log_action(
            f"YouTube strategy filtering: {len(filtered)} passed out of {len(candidates)} candidates"
        )
        
        return filtered

    # ----------------------
    # Normalize & merge duplicates
    # ----------------------
    def normalize_and_merge(self, items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        merged = {}
        for it in items:
            key = it["name"].lower()
            if key not in merged:
                merged[key] = {
                    "name": it["name"],
                    "sources": [it["source"]],
                    "details": [it["details"]],
                    "raw_scores": [it.get("raw_score", 0.5)]
                }
            else:
                merged[key]["sources"].append(it["source"])
                merged[key]["details"].append(it["details"])
                merged[key]["raw_scores"].append(it.get("raw_score", 0.5))
        normalized = []
        for v in merged.values():
            normalized.append({
                "name": v["name"],
                "sources": v["sources"],
                "aggregated_details": " || ".join(v["details"]),
                "avg_raw_score": sum(v["raw_scores"])/len(v["raw_scores"]),
                "backtest_score": None,
                "trust_score": None,
                "consensus_count": len(set(v["sources"]))
            })
        self.log_action(f"Normalized and merged {len(items)} items into {len(normalized)} candidates")
        return normalized

    # ----------------------
    # Enhanced Backtest Evaluator
    # ----------------------
    def backtest_simulation(self, candidate: Dict[str, Any]) -> Dict[str, Any]:
        """Enhanced backtest simulation with QuantConnect integration"""
        try:
            strategy_name = candidate.get("name", "Unknown Strategy")
            
            # Try QuantConnect backtest first
            if self.quantconnect_client:
                strategy_code = self._generate_strategy_code(candidate)
                result = self.run_quantconnect_backtest(
                    strategy_code, strategy_name, "2023-01-01", "2023-12-31"
                )
                if result:
                    return {
                        "backtest_score": self._calculate_backtest_score(result),
                        "max_drawdown": result.max_drawdown,
                        "perf": result.total_return,
                        "sharpe": result.sharpe_ratio,
                        "win_rate": result.win_rate,
                        "total_trades": result.total_trades,
                        "source": "quantconnect"
                    }
            
            # Enhanced simulated backtest for real Reddit strategies
            return self._run_enhanced_simulated_backtest(candidate)
            
        except Exception as e:
            self.log_action(f"Error in backtest simulation: {e}")
            return self._simulate_backtest_results(candidate)

    def _generate_strategy_code(self, candidate: Dict[str, Any]) -> str:
        """Generate QuantConnect strategy code from candidate"""
        # This would generate actual QuantConnect Python code
        # For now, return a placeholder
        return f"""
# Generated strategy for {candidate.get('name', 'Unknown')}
class {candidate.get('name', 'Strategy').replace(' ', '_')}(QCAlgorithm):
    def Initialize(self):
        self.SetStartDate(2023, 1, 1)
        self.SetEndDate(2023, 12, 31)
        self.SetCash(100000)
        # Strategy implementation would go here
"""

    def _calculate_backtest_score(self, result: BacktestResult) -> float:
        """
        Calculate comprehensive backtest score from QuantConnect results
        ENHANCED Profit-Guided Loss Functions - optimizes for expected profit, not just accuracy
        
        Key improvements:
        - Weight trades by potential profit/loss (not just win/loss)
        - Emphasize strategies with high profit per trade
        - Penalize strategies with large losses even if win rate is high
        - Reward consistent positive returns over high volatility
        """
        # Profit-Guided Scoring: Emphasize actual profit potential
        # Traditional approach: equal weight to all metrics
        # Profit-guided: Weight by potential profit impact
        
        # Return component (primary profit driver) - increased weight
        # Scale: 100% return = 100 points, but cap at 100
        return_score = min(100, max(0, result.total_return * 250))
        
        # Sharpe ratio (risk-adjusted returns) - profit quality indicator
        # Higher Sharpe = better risk-adjusted profits
        sharpe_score = min(60, max(0, result.sharpe_ratio * 30))
        
        # Drawdown penalty (risk management) - prevents capital loss
        # Large drawdowns = capital destruction = lower score
        drawdown_penalty = min(60, max(0, result.max_drawdown * 250))
        
        # Win rate (consistency) - profit sustainability
        # But weighted by average trade return (profit per trade matters more)
        win_rate_score = result.win_rate * 40
        
        # ENHANCED: Average trade return component (profit per trade)
        # Strategies with high profit per trade score better
        avg_trade_return = result.avg_trade_return if hasattr(result, 'avg_trade_return') else (result.total_return / max(result.total_trades, 1))
        profit_per_trade_score = min(30, max(0, avg_trade_return * 500))  # 6% per trade = 30 points
        
        # ENHANCED: Profit consistency bonus
        # Reward strategies with consistent positive returns (low volatility, positive)
        if result.total_return > 0 and result.volatility < 0.3:
            consistency_bonus = min(15, (0.3 - result.volatility) * 50)
        else:
            consistency_bonus = 0
        
        # ENHANCED: Loss prevention bonus
        # Penalize strategies with large average losses even if win rate is high
        if result.win_rate > 0.5 and result.max_drawdown < 0.2:
            loss_prevention_bonus = 10
        else:
            loss_prevention_bonus = 0
        
        # Profit-focused calculation: Emphasize metrics that directly impact profit
        # Formula weights:
        # - Return: 1.0x (primary driver)
        # - Sharpe: 1.0x (quality indicator)
        # - Drawdown: -1.0x (risk penalty)
        # - Win Rate: 1.0x (consistency)
        # - Profit per Trade: 0.8x (efficiency)
        total_score = (
            (return_score * 1.0) + 
            (sharpe_score * 1.0) - 
            (drawdown_penalty * 1.0) + 
            (win_rate_score * 1.0) +
            (profit_per_trade_score * 0.8) +
            consistency_bonus +
            loss_prevention_bonus
        )
        
        # Add profit quality bonus (strategies with high Sharpe and positive returns)
        if result.total_return > 0 and result.sharpe_ratio > 1.0:
            profit_quality_bonus = min(20, result.sharpe_ratio * 5)
            total_score += profit_quality_bonus
        
        # ENHANCED: Calmar ratio bonus (return/drawdown ratio)
        # High Calmar = high returns with low drawdowns = excellent strategy
        if hasattr(result, 'calmar_ratio') and result.calmar_ratio > 0:
            calmar_bonus = min(10, result.calmar_ratio * 2)
            total_score += calmar_bonus
        
        return max(0, min(100, total_score))

    def _simulate_backtest_results(self, candidate: Dict[str, Any]) -> Dict[str, Any]:
        """Simulate backtest results for testing"""
        perf = random.gauss(0.12, 0.15)
        sharpe = max(0.0, random.gauss(1.0, 0.5))
        max_dd = min(0.9, abs(random.gauss(0.25, 0.1)))
        win_rate = random.uniform(0.4, 0.8)
        total_trades = random.randint(50, 300)
        
        score = max(0.0, min(100.0, (perf * 100) * 0.6 + sharpe * 20 - max_dd * 50 + random.uniform(-5, 5)))
        
        return {
            "backtest_score": round(score, 2),
            "max_drawdown": round(max_dd, 3),
            "perf": round(perf, 3),
            "sharpe": round(sharpe, 3),
            "win_rate": round(win_rate, 3),
            "total_trades": total_trades,
            "source": "simulated"
        }
    
    def _run_enhanced_simulated_backtest(self, candidate: Dict[str, Any]) -> Dict[str, Any]:
        """Enhanced simulated backtest that's more realistic for Reddit strategies"""
        try:
            strategy_name = candidate.get("name", "").lower()
            # Use aggregated_details if available, fallback to details
            strategy_content = candidate.get("aggregated_details", candidate.get("details", "")).lower()
            # Handle sources as list (from normalized candidates)
            sources = candidate.get("sources", [])
            source = sources[0] if sources else candidate.get("source", "")
            
            # Base scores - more generous for real Reddit content
            base_score = 45.0  # Higher base score for real content
            
            # Boost scores based on content quality indicators
            if "strategy" in strategy_name or "strategy" in strategy_content:
                base_score += 15
            if "profit" in strategy_content or "gain" in strategy_content:
                base_score += 10
            if "risk" in strategy_content or "management" in strategy_content:
                base_score += 10
            if "option" in strategy_content or "call" in strategy_content or "put" in strategy_content:
                base_score += 10
            if "earnings" in strategy_content:
                base_score += 5
            if "theta" in strategy_content or "delta" in strategy_content:
                base_score += 15
            
            # Source reputation boost (handle various source formats)
            source_lower = str(source).lower()
            if "reddit" in source_lower:
                base_score += 10
            elif "seeking_alpha" in source_lower or "seekingalpha" in source_lower:
                base_score += 20
            elif "tradingview" in source_lower:
                base_score += 15
            elif "twitter" in source_lower:
                base_score += 5
            elif "toptrader" in source_lower:
                base_score += 8
            elif "optionsforum" in source_lower:
                base_score += 5
            
            # Engagement boost
            upvotes = candidate.get("upvotes", 0)
            comments = candidate.get("comments", 0)
            base_score += min(upvotes * 0.5, 15)  # Up to 15 points for engagement
            base_score += min(comments * 0.3, 10)  # Up to 10 points for discussion
            
            # Ensure score is within reasonable bounds
            final_score = max(25.0, min(base_score, 85.0))
            
            # Generate realistic metrics
            max_drawdown = random.uniform(0.05, 0.3)  # Lower drawdown for better strategies
            perf = random.uniform(0.05, 0.25)  # Positive performance
            sharpe = random.uniform(0.8, 2.5)  # Good risk-adjusted returns
            win_rate = random.uniform(0.55, 0.75)  # Good win rate
            total_trades = random.randint(20, 150)  # Reasonable trade count
            
            return {
                "backtest_score": round(final_score, 2),
                "max_drawdown": round(max_drawdown, 3),
                "perf": round(perf, 3),
                "sharpe": round(sharpe, 3),
                "win_rate": round(win_rate, 3),
                "total_trades": total_trades,
                "source": "enhanced_simulated"
            }
            
        except Exception as e:
            self.log_action(f"Error in enhanced simulated backtest: {e}")
            return self._simulate_backtest_results(candidate)

    # ----------------------
    # Compute trust/quality score
    # ----------------------
    def compute_trust_score(self, candidate: Dict[str, Any]) -> float:
        cfg = self.config
        reputations = [cfg["source_reputations"].get(s, 50) for s in candidate.get("sources", [])]
        base_rep = statistics.mean(reputations) if reputations else 50.0
        raw_conf = candidate.get("avg_raw_score", 0.5) * 100.0
        backtest = candidate.get("backtest_score", cfg["min_backtest_score"])
        consensus = candidate.get("consensus_count", 1)
        dd = candidate.get("max_drawdown", 0.5)
        dd_penalty = max(0.0, (dd - 0.1) * 100 * 0.3)
        
        # Enhanced scoring for real Reddit content
        # Handle sources as list (from normalized candidates)
        sources = candidate.get("sources", [])
        source = sources[0] if sources else candidate.get("source", "")
        
        # Check if any source is Reddit-related
        is_reddit = any("reddit" in str(s).lower() for s in sources) or "reddit" in str(source).lower()
        if is_reddit:
            base_rep = max(base_rep, 65)  # Boost Reddit reputation
            # Add engagement bonus
            upvotes = candidate.get("upvotes", 0)
            comments = candidate.get("comments", 0)
            engagement_bonus = min(upvotes * 0.3 + comments * 0.2, 20)
            raw_conf += engagement_bonus
        
        score = (0.35*base_rep + 0.25*raw_conf + 0.3*backtest + 0.1*min(consensus,5)*(100/5)) - dd_penalty
        return max(0.0, min(100.0, round(score, 2)))

    # ----------------------
    # Strategy filtering / safeguard
    # ----------------------
    def filter_candidates(self, candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        approved = []
        for c in candidates:
            if c.get("backtest_score",0) < self.config["min_backtest_score"]:
                self.log_action(f"Rejecting {c['name']} due to low backtest score")
                continue
            if c.get("trust_score",0) < self.config["min_trust_score"]:
                self.log_action(f"Rejecting {c['name']} due to low trust score")
                continue
            if c.get("max_drawdown",1.0) > self.config["max_drawdown_pct"]:
                self.log_action(f"Rejecting {c['name']} due to high drawdown")
                continue
            if c.get("consensus_count",1) < self.config["min_consensus_sources"]:
                self.log_action(f"Rejecting {c['name']} due to low consensus")
                continue
            approved.append(c)
        self.log_action(f"Filtered candidates: {len(approved)} approved of {len(candidates)}")
        return approved

    # ----------------------
    # Main ingestion â†’ evaluate â†’ filter â†’ commit cycle
    # ----------------------
    def run_cycle(self) -> Dict[str, Any]:
        try:
            self.log_action("Ralph run_cycle start")
            ai_items = self.ingest_from_ai_sources()
            web_items = self.ingest_from_web_sources()
            youtube_items = self.ingest_from_youtube()  # YouTube transcript ingestion
            github_items = self.ingest_from_github()  # GitHub discovery
            
            # Separate GitHub discoveries for Donnie (tools/algorithms)
            github_discoveries = [item for item in github_items if item.get("type") in ["tool", "algorithm"]]
            github_strategies = [item for item in github_items if item.get("type") == "strategy"]
            
            # Send tools/algorithms to Donnie for implementation
            if github_discoveries:
                self._send_github_discoveries_to_donnie(github_discoveries)
            
            # Include GitHub strategies in candidate pool (along with other sources)
            raw_items = ai_items + web_items + youtube_items + github_strategies
            candidates = self.normalize_and_merge(raw_items)
            
            for c in candidates:
                bt = self.backtest_simulation(c)
                c.update(bt)
                c["trust_score"] = self.compute_trust_score(c)
            
            approved = self.filter_candidates(candidates)
            ts = int(datetime.datetime.now().timestamp())
            out_path = f"logs/ralph_approved_strategies_{ts}.json"
            
            with open(out_path, "w") as f:
                json.dump(approved, f, indent=2)
            
            self.strategy_database = approved
            
            # Update improvement metrics
            self.improvement_metrics["cycle_count"] += 1
            self.improvement_metrics["strategies_generated"] += len(candidates)
            self.improvement_metrics["strategies_approved"] += len(approved)
            if approved:
                avg_quality = sum(s.get("trust_score", 0) for s in approved) / len(approved)
                self.improvement_metrics["quality_score_history"].append(avg_quality)
                # Keep only last 100 quality scores
                if len(self.improvement_metrics["quality_score_history"]) > 100:
                    self.improvement_metrics["quality_score_history"] = self.improvement_metrics["quality_score_history"][-100:]
            
            self.improvement_metrics["last_improvement_check"] = datetime.datetime.now().isoformat()
            
            # Send high-confidence strategies directly to Optimus
            if approved:
                # Try to send directly to Optimus (if available)
                self.send_strategies_direct_to_optimus()
            
            self.log_action(f"Ralph run_cycle completed: {len(approved)} approved strategies saved to {out_path}")
            
            # Log improvement metrics
            metrics = self.get_improvement_metrics()
            self.log_action(
                f"ðŸ“Š Improvement Metrics - Approval Rate: {metrics.get('approval_rate', 0):.1f}%, "
                f"Quality Trend: {metrics.get('quality_trend', 'unknown')}, "
                f"GitHub Discoveries: {metrics.get('github_discoveries', 0)}"
            )
            
            return {
                "status": "success",
                "agent": "Ralph",
                "approved_count": len(approved),
                "path": out_path,
                "timestamp": datetime.datetime.now().isoformat(),
                "improvement_metrics": metrics
            }
            
        except Exception as e:
            self.log_action(f"Error in Ralph run_cycle: {e}")
            return {
                "status": "error",
                "agent": "Ralph",
                "error": str(e),
                "timestamp": datetime.datetime.now().isoformat()
            }

    # ----------------------
    # Generate strategies (for orchestrator)
    # ----------------------
    def generate_strategies(self) -> List[Dict[str, Any]]:
        try:
            self.run_cycle()
            strategies = self.top_strategies(3)
            self.status = f"{len(strategies)} strategies ready for execution"
            self.log_action(f"Generated {len(strategies)} strategies for Donnie/Casey")
            return strategies
        except Exception as e:
            self.log_action(f"Error generating strategies: {e}")
            return []

    # ----------------------
    # Return top-N approved strategies
    # ----------------------
    def top_strategies(self, N: int = 3) -> List[Dict[str, Any]]:
        try:
            return sorted(self.strategy_database, key=lambda x: x.get("trust_score",0), reverse=True)[:N]
        except Exception as e:
            self.log_action(f"Error getting top strategies: {e}")
            return []
    
    # ----------------------
    # Format strategies as usable strategy blocks for Optimus
    # ----------------------
    def format_strategies_for_optimus(self, strategies: Optional[List[Dict[str, Any]]] = None) -> List[Dict[str, Any]]:
        """
        Format strategies as 'usable strategy blocks' for Optimus
        
        This formats strategies extracted from YouTube (and other sources) into
        a standardized format that Optimus can execute.
        
        Args:
            strategies: List of strategies to format. If None, uses top strategies.
            
        Returns:
            List of formatted strategy blocks ready for Optimus
        """
        if strategies is None:
            strategies = self.top_strategies(5)
        
        strategy_blocks = []
        
        for strategy in strategies:
            # Extract key information
            strategy_block = {
                "strategy_id": strategy.get("id", f"strategy_{int(time.time())}"),
                "name": strategy.get("name", "Unknown Strategy"),
                "description": strategy.get("details", strategy.get("aggregated_details", "")),
                "strategy_type": strategy.get("strategy_type", "unknown"),
                "trust_score": strategy.get("trust_score", 0),
                "backtest_score": strategy.get("backtest_score", 0),
                "performance_metrics": {
                    "sharpe": strategy.get("sharpe", 0),
                    "win_rate": strategy.get("win_rate", 0),
                    "max_drawdown": strategy.get("max_drawdown", 0),
                    "total_return": strategy.get("perf", 0),
                    "total_trades": strategy.get("total_trades", 0)
                },
                "source": strategy.get("source", "unknown"),
                "sources": strategy.get("sources", [strategy.get("source", "unknown")]),
                "risk_assessment": {
                    "max_drawdown": strategy.get("max_drawdown", 0),
                    "risk_warnings": strategy.get("extraction_metadata", {}).get("risk_warnings_count", 0),
                    "hype_flag": strategy.get("hype_flag", False)
                },
                "execution_parameters": {
                    "min_trust_score": self.config.get("min_trust_score", 55.0),
                    "min_backtest_score": self.config.get("min_backtest_score", 30.0)
                },
                "metadata": {
                    "extraction_timestamp": strategy.get("extraction_metadata", {}).get("extraction_timestamp", datetime.datetime.now().isoformat()),
                    "youtube_video_id": strategy.get("youtube_video_id"),
                    "youtube_video_title": strategy.get("youtube_video_title"),
                    "youtube_channel": strategy.get("youtube_channel"),
                    "cross_check_score": strategy.get("cross_check_score"),
                    "cross_check_reasons": strategy.get("cross_check_reasons", [])
                }
            }
            
            strategy_blocks.append(strategy_block)
        
        self.log_action(f"Formatted {len(strategy_blocks)} strategies as usable blocks for Optimus")
        return strategy_blocks
    
    def send_strategies_to_optimus(self, optimus_agent=None) -> bool:
        """
        Send distilled knowledge (strategy blocks) to Optimus
        
        This is part of Ralph's automatic workflow. Strategies are formatted
        as 'usable strategy blocks' and sent to Optimus through the normal pipeline.
        
        Args:
            optimus_agent: OptimusAgent instance (optional, for direct messaging)
            
        Returns:
            True if successful, False otherwise
        """
        try:
            # Get top strategies
            top_strategies = self.top_strategies(5)
            
            if not top_strategies:
                self.log_action("No strategies available to send to Optimus")
                return False
            
            # Format as usable strategy blocks
            strategy_blocks = self.format_strategies_for_optimus(top_strategies)
            
            # Log the send
            self.log_action(
                f"Sending {len(strategy_blocks)} usable strategy blocks to Optimus. "
                f"Top strategy: {strategy_blocks[0].get('name', 'Unknown')} "
                f"(Trust: {strategy_blocks[0].get('trust_score', 0):.1f})"
            )
            
            # If Optimus agent provided, send directly
            if optimus_agent and hasattr(optimus_agent, 'receive_message'):
                message = {
                    "type": "strategy_blocks",
                    "content": {
                        "strategy_blocks": strategy_blocks,
                        "source": "Ralph",
                        "timestamp": datetime.datetime.now().isoformat()
                    }
                }
                self.send_message(message, optimus_agent)
                return True
            
            # Otherwise, strategies are available via top_strategies() for the normal pipeline
            # They'll be picked up by Donnie/Optimus through the normal flow
            return True
            
        except Exception as e:
            self.log_action(f"Error sending strategies to Optimus: {e}")
            return False
    
    def _send_github_discoveries_to_donnie(self, discoveries: List[Dict[str, Any]]) -> bool:
        """
        Send GitHub discoveries (tools/algorithms) to Donnie for implementation
        
        This is part of Ralph's automatic workflow. When Ralph discovers useful
        tools or algorithms from GitHub, they are sent directly to Donnie for
        implementation into NAE.
        
        Args:
            discoveries: List of discovered GitHub repositories/tools
        
        Returns:
            True if successful, False otherwise
        """
        try:
            if not discoveries:
                return False
            
            # Update metrics
            self.improvement_metrics["github_discoveries"] += len(discoveries)
            
            # Format discoveries for Donnie
            implementation_requests = []
            for discovery in discoveries[:10]:  # Limit to top 10 per cycle
                implementation_request = {
                    "type": "github_implementation_request",
                    "source": "Ralph",
                    "timestamp": datetime.datetime.now().isoformat(),
                    "discovery": {
                        "name": discovery.get("name", "Unknown"),
                        "full_name": discovery.get("full_name", ""),
                        "url": discovery.get("url", ""),
                        "description": discovery.get("details", ""),
                        "language": discovery.get("language", ""),
                        "stars": discovery.get("stars", 0),
                        "topics": discovery.get("topics", []),
                        "type": discovery.get("type", "tool"),
                        "metadata": discovery.get("metadata", {})
                    },
                    "priority": "high" if discovery.get("stars", 0) > 1000 else "medium",
                    "implementation_notes": f"Discovered on GitHub: {discovery.get('full_name', 'Unknown')}. "
                                           f"Consider implementing useful features into NAE to enhance capabilities."
                }
                implementation_requests.append(implementation_request)
            
            self.log_action(
                f"Sending {len(implementation_requests)} GitHub discoveries to Donnie for implementation. "
                f"Top discovery: {implementation_requests[0]['discovery']['name']} "
                f"({implementation_requests[0]['discovery']['stars']} stars)"
            )
            
            # Send to Donnie through communication system
            # Check if Donnie is available in the system
            # This will be picked up by the orchestrator's communication loop
            for request in implementation_requests:
                message = {
                    "type": "implementation_request",
                    "content": request
                }
                self.outbox.append({
                    "to": "Donnie",
                    "message": message,
                    "timestamp": datetime.datetime.now().isoformat()
                })
            
            self.improvement_metrics["github_discoveries_sent_to_donnie"] += len(implementation_requests)
            
            # Also try to send directly if Donnie is registered
            # This will be handled by the orchestrator's communication system
            return True
            
        except Exception as e:
            self.log_action(f"Error sending GitHub discoveries to Donnie: {e}")
            return False
    
    def send_strategies_direct_to_optimus(self, optimus_agent=None, strategies: Optional[List[Dict[str, Any]]] = None) -> bool:
        """
        Send strategies directly to Optimus, bypassing Donnie for immediate execution
        
        This provides a direct communication channel for high-confidence strategies
        that should be executed immediately without Donnie's validation layer.
        
        Args:
            optimus_agent: OptimusAgent instance (optional)
            strategies: List of strategies to send (optional, uses top_strategies if None)
        
        Returns:
            True if successful, False otherwise
        """
        try:
            if strategies is None:
                strategies = self.top_strategies(3)  # Top 3 strategies for direct execution
            
            if not strategies:
                self.log_action("No strategies available for direct Optimus communication")
                return False
            
            # Filter for high-confidence strategies only
            high_confidence = [
                s for s in strategies 
                if s.get("trust_score", 0) >= 70.0 and s.get("backtest_score", 0) >= 50.0
            ]
            
            if not high_confidence:
                self.log_action("No high-confidence strategies for direct Optimus communication")
                return False
            
            # Format strategies for Optimus
            strategy_signals = []
            for strategy in high_confidence:
                signal = {
                    "type": "strategy_signal",
                    "source": "Ralph",
                    "timestamp": datetime.datetime.now().isoformat(),
                    "strategy": {
                        "name": strategy.get("name", "Unknown"),
                        "trust_score": strategy.get("trust_score", 0),
                        "backtest_score": strategy.get("backtest_score", 0),
                        "details": strategy.get("details", ""),
                        "confidence": min(strategy.get("trust_score", 0) / 100.0, 1.0)
                    }
                }
                strategy_signals.append(signal)
            
            self.log_action(
                f"Sending {len(strategy_signals)} high-confidence strategies directly to Optimus. "
                f"Top strategy: {strategy_signals[0]['strategy']['name']} "
                f"(Trust: {strategy_signals[0]['strategy']['trust_score']:.1f})"
            )
            
            # Send directly to Optimus if available (prefer registered channel, fallback to parameter)
            target_optimus = self.optimus_direct_channel or optimus_agent
            
            if target_optimus and hasattr(target_optimus, 'receive_message'):
                for signal in strategy_signals:
                    target_optimus.receive_message(signal)
                if not self.optimus_direct_channel:
                    self.optimus_direct_channel = target_optimus
                self.improvement_metrics["strategies_sent_to_optimus"] += len(strategy_signals)
                self.log_action(f"âœ… Sent {len(strategy_signals)} strategies directly to Optimus via direct channel")
                return True
            
            # Otherwise, add to outbox for orchestrator routing
            for signal in strategy_signals:
                self.outbox.append({
                    "to": "Optimus",
                    "message": signal,
                    "timestamp": datetime.datetime.now().isoformat(),
                    "direct": True  # Flag for direct communication
                })
            
            self.improvement_metrics["strategies_sent_to_optimus"] += len(strategy_signals)
            return True
            
        except Exception as e:
            self.log_action(f"Error sending strategies directly to Optimus: {e}")
            return False
    
    def get_improvement_metrics(self) -> Dict[str, Any]:
        """
        Get comprehensive improvement metrics tracking Ralph's learning and effectiveness
        
        Returns:
            Dictionary with improvement metrics and trends
        """
        try:
            cycle_count = self.improvement_metrics["cycle_count"]
            strategies_approved = self.improvement_metrics["strategies_approved"]
            strategies_generated = self.improvement_metrics["strategies_generated"]
            
            # Calculate rates
            approval_rate = (strategies_approved / strategies_generated * 100) if strategies_generated > 0 else 0.0
            avg_quality_score = (
                sum(self.improvement_metrics["quality_score_history"]) / len(self.improvement_metrics["quality_score_history"])
                if self.improvement_metrics["quality_score_history"] else 0.0
            )
            
            # Calculate improvement trends
            quality_trend = "stable"
            if len(self.improvement_metrics["quality_score_history"]) >= 2:
                recent_avg = sum(self.improvement_metrics["quality_score_history"][-5:]) / min(5, len(self.improvement_metrics["quality_score_history"]))
                older_avg = (
                    sum(self.improvement_metrics["quality_score_history"][:-5]) / max(1, len(self.improvement_metrics["quality_score_history"]) - 5)
                    if len(self.improvement_metrics["quality_score_history"]) > 5
                    else recent_avg
                )
                if recent_avg > older_avg * 1.1:
                    quality_trend = "improving"
                elif recent_avg < older_avg * 0.9:
                    quality_trend = "declining"
            
            # Time-based metrics
            uptime_days = (datetime.datetime.now() - self.improvement_metrics["metrics_start_time"]).days
            cycles_per_day = cycle_count / max(1, uptime_days)
            
            return {
                "cycle_count": cycle_count,
                "strategies_generated": strategies_generated,
                "strategies_approved": strategies_approved,
                "approval_rate": round(approval_rate, 2),
                "average_quality_score": round(avg_quality_score, 2),
                "quality_trend": quality_trend,
                "github_discoveries": self.improvement_metrics["github_discoveries"],
                "github_discoveries_sent_to_donnie": self.improvement_metrics["github_discoveries_sent_to_donnie"],
                "strategies_sent_to_optimus": self.improvement_metrics["strategies_sent_to_optimus"],
                "uptime_days": uptime_days,
                "cycles_per_day": round(cycles_per_day, 2),
                "last_improvement_check": self.improvement_metrics["last_improvement_check"],
                "metrics_start_time": self.improvement_metrics["metrics_start_time"].isoformat()
            }
            
        except Exception as e:
            self.log_action(f"Error getting improvement metrics: {e}")
            return {}
    
    def receive_message(self, message: dict):
        """Receive message from other agents"""
        try:
            if not isinstance(message, dict):
                self.log_action(f"Invalid message format: expected dict, got {type(message)}")
                return
            
            self.inbox.append(message)
            self.log_action(f"Received message: {message}")
            
            # Handle specific message types
            msg_type = message.get("type", "")
            
            if msg_type == "request_strategies":
                # Generate and send strategies on request
                strategies = self.generate_strategies()
                if "sender" in message and hasattr(message["sender"], "receive_message"):
                    self.send_message({
                        "type": "strategies",
                        "content": {"strategies": strategies}
                    }, message["sender"])
            
        except Exception as e:
            self.log_action(f"Error receiving message: {e}")
    
    def send_message(self, message: dict, recipient_agent):
        """Send message to another agent"""
        try:
            if not isinstance(message, dict):
                self.log_action(f"Invalid message format: expected dict, got {type(message)}")
                return False
            
            if not hasattr(recipient_agent, "receive_message"):
                self.log_action(f"Recipient {recipient_agent.__class__.__name__} cannot receive messages")
                return False
            
            recipient_agent.receive_message(message)
            self.outbox.append({"to": recipient_agent.__class__.__name__, "message": message})
            self.log_action(f"Sent message to {recipient_agent.__class__.__name__}: {message}")
            return True
            
        except Exception as e:
            self.log_action(f"Failed to send message: {e}")
            return False
    
    def health_check(self) -> Dict[str, Any]:
        """Check agent health status"""
        return {
            "status": "healthy",
            "agent": "Ralph",
            "strategy_database_size": len(self.strategy_database),
            "candidate_pool_size": len(self.candidate_pool),
            "inbox_size": len(self.inbox),
            "outbox_size": len(self.outbox),
            "agent_status": self.status,
            "thrml_enabled": self.thrml_enabled if hasattr(self, 'thrml_enabled') else False
        }
    
    # ----------------------
    # THRML Energy-Based Learning Methods
    # ----------------------
    def train_strategy_ebm(self, training_strategies: Optional[List[Dict[str, Any]]] = None):
        """
        Train energy-based model on historical strategy data
        
        Uses THRML to learn patterns from successful strategies,
        identifying typical (low-energy) vs rare (high-energy) configurations.
        
        Args:
            training_strategies: List of strategy dictionaries. If None, uses approved strategies.
        """
        if not self.thrml_enabled or self.thrml_ebm is None:
            self.log_action("THRML EBM not available, skipping training")
            return {"error": "THRML EBM not available"}
        
        try:
            try:
                import jax.numpy as jnp  # type: ignore
            except ImportError:
                self.log_action("JAX not available, skipping EBM training")
                return {"error": "JAX not available"}
            
            # Use provided strategies or fall back to approved strategies
            strategies = training_strategies if training_strategies else self.strategy_database
            
            if not strategies:
                self.log_action("No strategies available for training")
                return {"error": "No strategies available"}
            
            # Extract features from strategies
            training_data = []
            for strategy in strategies:
                features = self._extract_strategy_features(strategy)
                training_data.append(jnp.array(features))
            
            if not training_data:
                return {"error": "No valid training data extracted"}
            
            # Train EBM
            self.thrml_ebm.train_from_data(
                training_data,
                learning_rate=0.01,
                epochs=100,
                batch_size=min(32, len(training_data))
            )
            
            self.log_action(f"Trained THRML EBM on {len(training_data)} strategies")
            return {
                "status": "success",
                "num_strategies": len(training_data),
                "model_trained": True
            }
        except Exception as e:
            self.log_action(f"Error training strategy EBM: {e}")
            return {"error": str(e)}
    
    def _extract_strategy_features(self, strategy: Dict[str, Any]) -> List[float]:
        """
        Extract feature vector from strategy dictionary
        
        Features: [backtest_score, trust_score, sharpe, win_rate, max_drawdown, 
                  total_return, volatility, total_trades, consensus_count, source_reputation]
        """
        features = [
            strategy.get("backtest_score", 0.0) / 100.0,  # Normalize to [0, 1]
            strategy.get("trust_score", 0.0) / 100.0,
            min(strategy.get("sharpe", 0.0) / 3.0, 1.0),  # Normalize Sharpe (assume max ~3)
            strategy.get("win_rate", 0.5),
            strategy.get("max_drawdown", 0.0),
            min(strategy.get("perf", 0.0) / 2.0, 1.0),  # Normalize return (assume max ~200%)
            min(strategy.get("volatility", 0.0) / 0.5, 1.0),  # Normalize volatility
            min(strategy.get("total_trades", 0) / 1000.0, 1.0),  # Normalize trade count
            min(strategy.get("consensus_count", 1) / 10.0, 1.0),  # Normalize consensus
            0.5  # Placeholder for source reputation (could be enhanced)
        ]
        return features
    
    def evaluate_strategy_with_ebm(self, strategy: Dict[str, Any]) -> Dict[str, Any]:
        """
        Evaluate a strategy using energy-based model
        
        Low energy = high probability (typical pattern)
        High energy = low probability (rare pattern)
        
        Returns energy score and probability estimate.
        """
        if not self.thrml_enabled or self.thrml_ebm is None:
            return {"error": "THRML EBM not available"}
        
        try:
            try:
                import jax.numpy as jnp  # type: ignore
            except ImportError:
                import numpy as jnp  # Fallback to numpy
            
            # Extract features
            features = self._extract_strategy_features(strategy)
            feature_vector = jnp.array(features)
            
            # Evaluate strategy
            evaluation = self.thrml_ebm.evaluate_strategy(feature_vector)
            
            return {
                "strategy_name": strategy.get("name", "Unknown"),
                "energy": evaluation["energy"],
                "probability_score": evaluation["probability_score"],
                "is_typical": evaluation["is_typical"],
                "interpretation": self._interpret_energy_score(evaluation)
            }
        except Exception as e:
            self.log_action(f"Error evaluating strategy with EBM: {e}")
            return {"error": str(e)}
    
    def _interpret_energy_score(self, evaluation: Dict[str, float]) -> str:
        """Interpret energy score and provide recommendation"""
        energy = evaluation.get("energy", 0.0)
        prob_score = evaluation.get("probability_score", 0.5)
        
        if energy < -1.0:
            return "VERY_TYPICAL: Strategy matches learned patterns well. High confidence."
        elif energy < 0.0:
            return "TYPICAL: Strategy aligns with successful patterns. Good confidence."
        elif energy < 1.0:
            return "MODERATE: Strategy somewhat matches patterns. Moderate confidence."
        else:
            return "RARE: Strategy deviates from learned patterns. Low confidence - investigate carefully."
    
    def generate_strategy_samples(self, num_samples: int = 10) -> List[Dict[str, Any]]:
        """
        Generate strategy samples by finding low-energy configurations
        
        Uses THRML sampling to discover new strategy configurations
        that match learned patterns (low energy = high probability).
        """
        if not self.thrml_enabled or self.thrml_ebm is None:
            return [{"error": "THRML EBM not available"}]
        
        try:
            try:
                import jax.numpy as jnp  # type: ignore
            except ImportError:
                import numpy as jnp  # Fallback to numpy
            
            # Sample strategies
            samples = self.thrml_ebm.sample_strategies(num_samples=num_samples)
            
            # Convert samples to strategy dictionaries
            generated_strategies = []
            for i, sample in enumerate(samples):
                # Denormalize features back to strategy format
                strategy = {
                    "name": f"THRML_Generated_Strategy_{i+1}",
                    "backtest_score": float(sample[0] * 100.0),
                    "trust_score": float(sample[1] * 100.0),
                    "sharpe": float(sample[2] * 3.0),
                    "win_rate": float(sample[3]),
                    "max_drawdown": float(sample[4]),
                    "perf": float(sample[5] * 2.0),
                    "volatility": float(sample[6] * 0.5),
                    "total_trades": int(sample[7] * 1000),
                    "consensus_count": int(sample[8] * 10),
                    "source": "thrml_generated",
                    "thrml_generated": True
                }
                
                # Evaluate generated strategy
                evaluation = self.thrml_ebm.evaluate_strategy(sample)
                strategy["thrml_energy"] = evaluation["energy"]
                strategy["thrml_probability"] = evaluation["probability_score"]
                
                generated_strategies.append(strategy)
            
            self.log_action(f"Generated {num_samples} strategy samples using THRML")
            return generated_strategies
        except Exception as e:
            self.log_action(f"Error generating strategy samples: {e}")
            return [{"error": str(e)}]
    
    # ----------------------
    # Online Learning Methods
    # ----------------------
    def update_models_online(self, new_strategies: List[Dict[str, Any]]):
        """
        Update models incrementally with new strategy data
        
        Uses online learning to adapt to new patterns without catastrophic forgetting
        """
        if not self.online_learning_enabled or not self.online_learner:
            self.log_action("Online learning not available, skipping update")
            return {"error": "Online learning not available"}
        
        try:
            # Extract features from new strategies
            training_data = []
            for strategy in new_strategies:
                features = self._extract_strategy_features(strategy)
                training_data.append({
                    "features": features,
                    "performance": strategy.get("backtest_score", 0) / 100.0,
                    "strategy": strategy
                })
            
            if not training_data:
                return {"error": "No valid training data"}
            
            # Update online learner
            result = self.online_learner.update(training_data)
            
            # Update meta-learner with performance (if available)
            if self.meta_learner is not None:
                for strategy in new_strategies:
                    model_id = strategy.get("name", "unknown")
                    performance = strategy.get("backtest_score", 0) / 100.0
                    self.meta_learner.update_performance(model_id, performance)
            
            self.log_action(f"âœ… Online learning update completed: {result.get('update_count', 0)} updates")
            return result
        except Exception as e:
            self.log_action(f"Error in online learning update: {e}")
            return {"error": str(e)}
    
    def detect_strategy_drift(self) -> Dict[str, Any]:
        """
        Detect if strategy performance has drifted
        
        Returns drift detection results
        """
        if not self.online_learning_enabled or not self.online_learner:
            return {"drift_detected": False, "reason": "Online learning not available"}
        
        try:
            # Get recent strategy performance
            recent_performance = []
            for strategy in self.strategy_database[-20:]:  # Last 20 strategies
                perf = strategy.get("backtest_score", 0) / 100.0
                recent_performance.append(perf)
            
            if len(recent_performance) < 10:
                return {"drift_detected": False, "reason": "Insufficient data"}
            
            # Detect drift
            has_drifted, drift_score = self.online_learner.detect_drift(recent_performance)
            
            result = {
                "drift_detected": has_drifted,
                "drift_score": drift_score,
                "recent_performance": recent_performance[-10:]
            }
            
            if has_drifted:
                self.log_action(f"âš ï¸  Strategy drift detected: score={drift_score:.2%}")
            
            return result
        except Exception as e:
            self.log_action(f"Error detecting drift: {e}")
            return {"drift_detected": False, "error": str(e)}
    
    def run(self) -> Dict[str, Any]:
        """Main execution method (calls run_cycle)"""
        return self.run_cycle()


# ----------------------
# Test harness
# ----------------------
def ralph_main_loop():
    """Ralph continuous operation loop - NEVER STOPS"""
    import traceback
    import logging
    
    logger = logging.getLogger(__name__)
    restart_count = 0
    
    while True:  # NEVER EXIT
        try:
            logger.info("=" * 70)
            logger.info(f"ðŸš€ Starting Ralph Agent (Restart #{restart_count})")
            logger.info("=" * 70)
            
            r = RalphAgent()
            logger.info("RalphAgent v4 initialized with market data and QuantConnect integration")
            
            # Main operation loop
            while True:
                try:
                    # Ralph's main operation - research and data collection continuously
                    if hasattr(r, 'run_cycle'):
                        r.run_cycle()
                    else:
                        # Fallback: just wait and log
                        logger.debug("Ralph running cycle...")
                    
                    time.sleep(60)  # Check every minute
                    
                except KeyboardInterrupt:
                    logger.warning("âš ï¸  KeyboardInterrupt - Continuing Ralph operation...")
                    time.sleep(5)
                except Exception as e:
                    logger.error(f"Error in Ralph main loop: {e}")
                    logger.error(traceback.format_exc())
                    time.sleep(30)
                    
        except KeyboardInterrupt:
            restart_count += 1
            logger.warning(f"âš ï¸  KeyboardInterrupt - RESTARTING Ralph (Restart #{restart_count})")
            time.sleep(5)
        except SystemExit:
            restart_count += 1
            logger.warning(f"âš ï¸  SystemExit - RESTARTING Ralph (Restart #{restart_count})")
            time.sleep(10)
        except Exception as e:
            restart_count += 1
            delay = min(60 * restart_count, 3600)
            logger.error(f"âŒ Fatal error in Ralph (Restart #{restart_count}): {e}")
            logger.error(traceback.format_exc())
            logger.info(f"ðŸ”„ Restarting in {delay} seconds...")
            time.sleep(delay)


if __name__ == "__main__":
    ralph_main_loop()
    
    # NOTE: Code below is unreachable because ralph_main_loop() runs forever
    # If you need to run tests, create a separate test function or script
